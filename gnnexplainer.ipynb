{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "data = Data(...)  # A homogeneous graph data object.\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',  # Model returns log probabilities.\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Generate explanation for the node at index `10`:\n",
    "explanation = explainer(data.x, data.edge_index, index=10)\n",
    "print(explanation.edge_mask)\n",
    "print(explanation.node_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=Ellipsis)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with this version\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.explain.config import ModelConfig\n",
    "import torch_geometric as pyg\n",
    "\n",
    "# Assuming the LitGNN model and the data loader are already provided and correctly set up\n",
    "\n",
    "# Your existing GNN model (assumed to be using DGL, but adapted for PyTorch Geometric Explainer)\n",
    "\n",
    "# Define the function that sets up and runs GNNExplainer\n",
    "def run_gnn_explainer(model, data, node_idx, explain_node=True):\n",
    "    \"\"\"\n",
    "    Runs GNNExplainer to explain a node's feature contribution to the model's prediction.\n",
    "    \n",
    "    :param model: The GNN model (LitGNN in this case)\n",
    "    :param data_loader: The DataLoader containing graphs (DGL graph objects)\n",
    "    :param node_idx: The index of the node to explain\n",
    "    :param explain_node: If True, explain node classification, otherwise edge classification\n",
    "    \"\"\"\n",
    "    # Assuming you have a batch of graphs from your data_loader\n",
    "    for batch in data.test_dataloader():\n",
    "        graph = batch  # Your DGL graph or the data for this batch\n",
    "        # Ensure you can get node features and labels\n",
    "        node_features = graph.ndata['_CODEBERT']  # Example: node features stored under this key\n",
    "        labels = graph.ndata['_VULN']  # Example: node labels (vulnerable or not)\n",
    "        # Define the model configuration required for the explainer\n",
    "        model_config = ModelConfig(\n",
    "            mode='multiclass_classification',  # The model's task type: 'multiclass_classification', 'regression'\n",
    "            task_level='node',  # The task type: 'node' or 'edge' classification\n",
    "            return_type='log_probs'  # The type of output your model returns: 'log_probs', 'prob', or 'raw'\n",
    "        )\n",
    "        # Wrap your model into PyTorch Geometric Explainer\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GNNExplainer(),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='object',  # Node feature mask\n",
    "            edge_mask_type='object',  # Edge mask (optional, if you also want to explain edges)\n",
    "            model_config=model_config  # Pass the model configuration here\n",
    "        )\n",
    "        # Convert DGL graph to PyTorch Geometric's format\n",
    "        edge_index = torch.stack(graph.edges())  # Extract edge indices from DGL graph\n",
    "\n",
    "        # Explain for a specific node in the graph\n",
    "         # Apply the explainer to the node of interest\n",
    "        explanation = explainer(\n",
    "            x=node_features,  # The node features\n",
    "            edge_index=edge_index,  # The edge index from the DGL graph\n",
    "            index=0  # The index of the node to explain\n",
    "        )\n",
    "        \n",
    "        # Now you can visualize the feature contributions using explanation object\n",
    "        print(f\"Explanation for node {node_idx}:\\n\", explanation)\n",
    "\n",
    "        # If you want to visualize the explanation (optional)\n",
    "        explainer.visualize_subgraph(node_idx, graph.edge_index, explanation.edge_mask)\n",
    "\n",
    "        # Breaking after the first batch; for demonstration purposes\n",
    "        break\n",
    "\n",
    "# Call the function after training your model, passing in the model and data loader\n",
    "node_to_explain = 0  # The node index to explain\n",
    "run_gnn_explainer(model, data, node_to_explain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Grad-CAM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "\n",
    "class GNNGradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Hook for getting gradients\n",
    "        def save_grad(grad):\n",
    "            self.gradients = grad\n",
    "        \n",
    "        # Hook for getting activations\n",
    "        def save_activation(module, input, output):\n",
    "            self.activations = output\n",
    "            # Ensure that the activations require gradients\n",
    "            self.activations.retain_grad()\n",
    "\n",
    "        # Register hook to capture the activations and gradients at the target layer\n",
    "        self.model.gat2.register_forward_hook(save_activation)\n",
    "        self.model.gat2.register_full_backward_hook(lambda module, grad_in, grad_out: grad_out[0].register_hook(save_grad))\n",
    "\n",
    "    def forward(self, g):\n",
    "        \"\"\"Forward pass through the model\"\"\"\n",
    "        return self.model(g)\n",
    "\n",
    "    def backward(self, class_idx, logits):\n",
    "        \"\"\"Compute gradients with respect to the target class\"\"\"\n",
    "        self.model.zero_grad()  # Clear previous gradients\n",
    "        one_hot_output = torch.zeros_like(logits)\n",
    "        one_hot_output[:, class_idx] = 1  # Target the specific class for which you want the Grad-CAM\n",
    "        logits.backward(gradient=one_hot_output, retain_graph=True)\n",
    "\n",
    "    def generate_cam(self):\n",
    "        \"\"\"Generate the CAM by computing weighted sum of the gradients and activations\"\"\"\n",
    "        weights = torch.mean(self.gradients, dim=0)  # Compute average weights\n",
    "        cam = torch.zeros(self.activations.shape[0], self.activations.shape[1])\n",
    "        \n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * self.activations[:, i]\n",
    "        \n",
    "        # Apply ReLU\n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        # Normalize the CAM for visualization\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "        \n",
    "        return cam\n",
    "\n",
    "# Example usage\n",
    "model = model  # Initialize the pre-configured model with your setup\n",
    "gradcam = GNNGradCAM(model)\n",
    "\n",
    "# Example batch (replace with actual batch from your data loader)\n",
    "for batch in data.train_dataloader():\n",
    "    g = batch  # DGL graph batch\n",
    "    break\n",
    "\n",
    "# Forward pass\n",
    "logits, _ = gradcam.forward(g)\n",
    "\n",
    "# Pick a target class to compute Grad-CAM for (e.g., class 1)\n",
    "class_idx = 1\n",
    "gradcam.backward(class_idx, logits)\n",
    "\n",
    "# Generate CAM\n",
    "cam = gradcam.generate_cam()\n",
    "\n",
    "# Visualize or print CAM (e.g., feature importance for each node)\n",
    "print(cam)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

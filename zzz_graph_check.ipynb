{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl import load_graphs\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=4, num_edges=17,\n",
       "      ndata_schemes={'_FVULN': Scheme(shape=(), dtype=torch.float32), '_CVEVuldesc': Scheme(shape=(768,), dtype=torch.float32), '_VULN': Scheme(shape=(), dtype=torch.float32), '_LINE': Scheme(shape=(), dtype=torch.int32), '_RANDFEAT': Scheme(shape=(100,), dtype=torch.float32), '_FUNC_EMB': Scheme(shape=(768,), dtype=torch.float32), '_CODEBERT': Scheme(shape=(768,), dtype=torch.float32)}\n",
       "      edata_schemes={'_ETYPE': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/New_move/DomainGraph/storage/cache/bigvul_linevd_codebert_pdg+raw/6203\"\n",
    "g = load_graphs(path)[0][0]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5037, -0.5552, -0.6512,  ..., -0.0780,  0.0316,  0.1018],\n",
       "        [ 0.5037, -0.5552, -0.6512,  ..., -0.0780,  0.0316,  0.1018],\n",
       "        [ 0.5037, -0.5552, -0.6512,  ..., -0.0780,  0.0316,  0.1018],\n",
       "        [ 0.5037, -0.5552, -0.6512,  ..., -0.0780,  0.0316,  0.1018]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['_CVEVuldesc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4848951000000001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9811951+0.5037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5025, -0.5150, -0.6178,  ..., -0.1697, -0.0045,  0.1394],\n",
       "        [ 0.5025, -0.5150, -0.6178,  ..., -0.1697, -0.0045,  0.1394],\n",
       "        [ 0.5025, -0.5150, -0.6178,  ..., -0.1697, -0.0045,  0.1394],\n",
       "        [ 0.5025, -0.5150, -0.6178,  ..., -0.1697, -0.0045,  0.1394]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['_FUNC_EMB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('_N', '_E', '_N')]\n"
     ]
    }
   ],
   "source": [
    "print(g.canonical_etypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.stack(g.edges()) \n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m node_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m node_index\n",
      "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "node_index = torch.stack(g.nodes())\n",
    "node_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DGLGraph' object has no attribute 'node_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_index\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DGLGraph' object has no attribute 'node_index'"
     ]
    }
   ],
   "source": [
    "g.node_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 768), (4, 768))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm  \n",
    "\n",
    "A = np.array(g.ndata['_CVEVuldesc'])\n",
    "B =  np.array(g.ndata['_FUNC_EMB'])\n",
    "A.shape , B.shape\n",
    "# cosine_sim = np.dot(A, B) /(norm(A)*norm(B))\n",
    "# cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3072 into shape (768,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3072 into shape (768,1)"
     ]
    }
   ],
   "source": [
    "A.reshape(768, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['_FVULN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      "[[0.9811951 0.9811951 0.9811951 0.9811951]\n",
      " [0.9811951 0.9811951 0.9811951 0.9811951]\n",
      " [0.9811951 0.9811951 0.9811951 0.9811951]\n",
      " [0.9811951 0.9811951 0.9811951 0.9811951]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(vara, varb):\n",
    "    \"\"\"This function compute and return the cosine simiarity between two variables\"\"\"\n",
    "    dot_product = np.dot(vara, varb.T)\n",
    "    norm_vara = np.linalg.norm(vara, axis=1, keepdims=True)\n",
    "    norm_varb = np.linalg.norm(varb, axis=1, keepdims=True)\n",
    "    \n",
    "    cos_similarity = dot_product / (norm_vara * norm_varb.T)\n",
    "    return cos_similarity\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_matrix = cosine_similarity(vara, varb)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811951"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4930, -0.5053, -0.6062,  ..., -0.1665, -0.0044,  0.1368],\n",
       "        [ 0.4930, -0.5053, -0.6062,  ..., -0.1665, -0.0044,  0.1368],\n",
       "        [ 0.4930, -0.5053, -0.6062,  ..., -0.1665, -0.0044,  0.1368],\n",
       "        [ 0.4930, -0.5053, -0.6062,  ..., -0.1665, -0.0044,  0.1368]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['_FUNC_EMB'] = np.max(similarity_matrix)*g.ndata['_FUNC_EMB']\n",
    "g.ndata['_FUNC_EMB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### code for GNN explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 349\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m#from torch_geometric.nn import GNNExplainer\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Initialize the GNNExplainer and visualize feature importance for a specific node\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLitGNNExplainer\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, epochs\u001b[38;5;241m=\u001b[39mmax_epochs):\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n",
      "Cell \u001b[0;32mIn[33], line 350\u001b[0m, in \u001b[0;36mLitGNNExplainer\u001b[0;34m()\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLitGNNExplainer\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, epochs\u001b[38;5;241m=\u001b[39m\u001b[43mmax_epochs\u001b[49m):\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m GNNExplainer(model, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Adjust `return_type` as needed\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#------------------\n",
    "from math import sqrt\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch_geometric.explain import ExplainerConfig, Explanation, ModelConfig\n",
    "from torch_geometric.explain.algorithm import ExplainerAlgorithm\n",
    "from torch_geometric.explain.algorithm.utils import clear_masks, set_masks\n",
    "from torch_geometric.explain.config import MaskType, ModelMode, ModelTaskLevel\n",
    "\n",
    "class GNNExplainer(ExplainerAlgorithm):\n",
    "    r\"\"\"The GNN-Explainer model from the `\"GNNExplainer: Generating\n",
    "    Explanations for Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph\n",
    "    structures and node features that play a crucial role in the predictions\n",
    "    made by a GNN.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using :class:`GNNExplainer`, see\n",
    "        `examples/explain/gnn_explainer.py <https://github.com/pyg-team/\n",
    "        pytorch_geometric/blob/master/examples/explain/gnn_explainer.py>`_,\n",
    "        `examples/explain/gnn_explainer_ba_shapes.py <https://github.com/\n",
    "        pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        explain/gnn_explainer_ba_shapes.py>`_, and `examples/explain/\n",
    "        gnn_explainer_link_pred.py <https://github.com/pyg-team/\n",
    "        pytorch_geometric/blob/master/examples/explain/gnn_explainer_link_pred.py>`_.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        The :obj:`edge_size` coefficient is multiplied by the number of nodes\n",
    "        in the explanation at every iteration, and the resulting value is added\n",
    "        to the loss as a regularization term, with the goal of producing\n",
    "        compact explanations.\n",
    "        A higher value will push the algorithm towards explanations with less\n",
    "        elements.\n",
    "        Consider adjusting the :obj:`edge_size` coefficient according to the\n",
    "        average node degree in the dataset, especially if this value is bigger\n",
    "        than in the datasets used in the original paper.\n",
    "\n",
    "    Args:\n",
    "        epochs (int, optional): The number of epochs to train.\n",
    "            (default: :obj:`100`)\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.01`)\n",
    "        **kwargs (optional): Additional hyper-parameters to override default\n",
    "            settings in\n",
    "            :attr:`~torch_geometric.explain.algorithm.GNNExplainer.coeffs`.\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.005,\n",
    "        'edge_reduction': 'sum',\n",
    "        'node_feat_size': 1.0,\n",
    "        'node_feat_reduction': 'mean',\n",
    "        'edge_ent': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "        'EPS': 1e-15,\n",
    "    }\n",
    "\n",
    "    def __init__(self, epochs: int = 100, lr: float = 0.01, **kwargs):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.coeffs.update(kwargs)\n",
    "\n",
    "        self.node_mask = self.hard_node_mask = None\n",
    "        self.edge_mask = self.hard_edge_mask = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        **kwargs,\n",
    "    ) -> Explanation:\n",
    "        if isinstance(x, dict) or isinstance(edge_index, dict):\n",
    "            raise ValueError(f\"Heterogeneous graphs not yet supported in \"\n",
    "                             f\"'{self.__class__.__name__}'\")\n",
    "\n",
    "        self._train(model, x, edge_index, target=target, index=index, **kwargs)\n",
    "\n",
    "        node_mask = self._post_process_mask(\n",
    "            self.node_mask,\n",
    "            self.hard_node_mask,\n",
    "            apply_sigmoid=True,\n",
    "        )\n",
    "        edge_mask = self._post_process_mask(\n",
    "            self.edge_mask,\n",
    "            self.hard_edge_mask,\n",
    "            apply_sigmoid=True,\n",
    "        )\n",
    "\n",
    "        self._clean_model(model)\n",
    "\n",
    "        return Explanation(node_mask=node_mask, edge_mask=edge_mask)\n",
    "\n",
    "    def supports(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def _train(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self._initialize_masks(x, edge_index)\n",
    "\n",
    "        parameters = []\n",
    "        if self.node_mask is not None:\n",
    "            parameters.append(self.node_mask)\n",
    "        if self.edge_mask is not None:\n",
    "            set_masks(model, self.edge_mask, edge_index, apply_sigmoid=True)\n",
    "            parameters.append(self.edge_mask)\n",
    "\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            h = x if self.node_mask is None else x * self.node_mask.sigmoid()\n",
    "            y_hat, y = model(h, edge_index, **kwargs), target\n",
    "\n",
    "            if index is not None:\n",
    "                y_hat, y = y_hat[index], y[index]\n",
    "\n",
    "            loss = self._loss(y_hat, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # In the first iteration, we collect the nodes and edges that are\n",
    "            # involved into making the prediction. These are all the nodes and\n",
    "            # edges with gradient != 0 (without regularization applied).\n",
    "            if i == 0 and self.node_mask is not None:\n",
    "                if self.node_mask.grad is None:\n",
    "                    raise ValueError(\"Could not compute gradients for node \"\n",
    "                                     \"features. Please make sure that node \"\n",
    "                                     \"features are used inside the model or \"\n",
    "                                     \"disable it via `node_mask_type=None`.\")\n",
    "                self.hard_node_mask = self.node_mask.grad != 0.0\n",
    "            if i == 0 and self.edge_mask is not None:\n",
    "                if self.edge_mask.grad is None:\n",
    "                    raise ValueError(\"Could not compute gradients for edges. \"\n",
    "                                     \"Please make sure that edges are used \"\n",
    "                                     \"via message passing inside the model or \"\n",
    "                                     \"disable it via `edge_mask_type=None`.\")\n",
    "                self.hard_edge_mask = self.edge_mask.grad != 0.0\n",
    "\n",
    "    def _initialize_masks(self, x: Tensor, edge_index: Tensor):\n",
    "        node_mask_type = self.explainer_config.node_mask_type\n",
    "        edge_mask_type = self.explainer_config.edge_mask_type\n",
    "\n",
    "        device = x.device\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        if node_mask_type is None:\n",
    "            self.node_mask = None\n",
    "        elif node_mask_type == MaskType.object:\n",
    "            self.node_mask = Parameter(torch.randn(N, 1, device=device) * std)\n",
    "        elif node_mask_type == MaskType.attributes:\n",
    "            self.node_mask = Parameter(torch.randn(N, F, device=device) * std)\n",
    "        elif node_mask_type == MaskType.common_attributes:\n",
    "            self.node_mask = Parameter(torch.randn(1, F, device=device) * std)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        if edge_mask_type is None:\n",
    "            self.edge_mask = None\n",
    "        elif edge_mask_type == MaskType.object:\n",
    "            std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "            self.edge_mask = Parameter(torch.randn(E, device=device) * std)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def _loss(self, y_hat: Tensor, y: Tensor) -> Tensor:\n",
    "        if self.model_config.mode == ModelMode.binary_classification:\n",
    "            loss = self._loss_binary_classification(y_hat, y)\n",
    "        elif self.model_config.mode == ModelMode.multiclass_classification:\n",
    "            loss = self._loss_multiclass_classification(y_hat, y)\n",
    "        elif self.model_config.mode == ModelMode.regression:\n",
    "            loss = self._loss_regression(y_hat, y)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        if self.hard_edge_mask is not None:\n",
    "            assert self.edge_mask is not None\n",
    "            m = self.edge_mask[self.hard_edge_mask].sigmoid()\n",
    "            edge_reduce = getattr(torch, self.coeffs['edge_reduction'])\n",
    "            loss = loss + self.coeffs['edge_size'] * edge_reduce(m)\n",
    "            ent = -m * torch.log(m + self.coeffs['EPS']) - (\n",
    "                1 - m) * torch.log(1 - m + self.coeffs['EPS'])\n",
    "            loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "        if self.hard_node_mask is not None:\n",
    "            assert self.node_mask is not None\n",
    "            m = self.node_mask[self.hard_node_mask].sigmoid()\n",
    "            node_reduce = getattr(torch, self.coeffs['node_feat_reduction'])\n",
    "            loss = loss + self.coeffs['node_feat_size'] * node_reduce(m)\n",
    "            ent = -m * torch.log(m + self.coeffs['EPS']) - (\n",
    "                1 - m) * torch.log(1 - m + self.coeffs['EPS'])\n",
    "            loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _clean_model(self, model):\n",
    "        clear_masks(model)\n",
    "        self.node_mask = self.hard_node_mask = None\n",
    "        self.edge_mask = self.hard_edge_mask = None\n",
    "\n",
    "\n",
    "class GNNExplainer_:\n",
    "    r\"\"\"Deprecated version for :class:`GNNExplainer`.\"\"\"\n",
    "\n",
    "    coeffs = GNNExplainer.coeffs\n",
    "\n",
    "    conversion_node_mask_type = {\n",
    "        'feature': 'common_attributes',\n",
    "        'individual_feature': 'attributes',\n",
    "        'scalar': 'object',\n",
    "    }\n",
    "\n",
    "    conversion_return_type = {\n",
    "        'log_prob': 'log_probs',\n",
    "        'prob': 'probs',\n",
    "        'raw': 'raw',\n",
    "        'regression': 'raw',\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        epochs: int = 100,\n",
    "        lr: float = 0.01,\n",
    "        return_type: str = 'log_prob',\n",
    "        feat_mask_type: str = 'feature',\n",
    "        allow_edge_mask: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        assert feat_mask_type in ['feature', 'individual_feature', 'scalar']\n",
    "\n",
    "        explainer_config = ExplainerConfig(\n",
    "            explanation_type='model',\n",
    "            node_mask_type=self.conversion_node_mask_type[feat_mask_type],\n",
    "            edge_mask_type=MaskType.object if allow_edge_mask else None,\n",
    "        )\n",
    "        model_config = ModelConfig(\n",
    "            mode='regression'\n",
    "            if return_type == 'regression' else 'multiclass_classification',\n",
    "            task_level=ModelTaskLevel.node,\n",
    "            return_type=self.conversion_return_type[return_type],\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "        self._explainer = GNNExplainer(epochs=epochs, lr=lr, **kwargs)\n",
    "        self._explainer.connect(explainer_config, model_config)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_initial_prediction(self, *args, **kwargs) -> Tensor:\n",
    "\n",
    "        training = self.model.training\n",
    "        self.model.eval()\n",
    "\n",
    "        out = self.model(*args, **kwargs)\n",
    "        if (self._explainer.model_config.mode ==\n",
    "                ModelMode.multiclass_classification):\n",
    "            out = out.argmax(dim=-1)\n",
    "\n",
    "        self.model.train(training)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def explain_graph(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        self._explainer.model_config.task_level = ModelTaskLevel.graph\n",
    "\n",
    "        explanation = self._explainer(\n",
    "            self.model,\n",
    "            x,\n",
    "            edge_index,\n",
    "            target=self.get_initial_prediction(x, edge_index, **kwargs),\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self._convert_output(explanation, edge_index)\n",
    "\n",
    "    def explain_node(\n",
    "        self,\n",
    "        node_idx: int,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        self._explainer.model_config.task_level = ModelTaskLevel.node\n",
    "        explanation = self._explainer(\n",
    "            self.model,\n",
    "            x,\n",
    "            edge_index,\n",
    "            target=self.get_initial_prediction(x, edge_index, **kwargs),\n",
    "            index=node_idx,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self._convert_output(explanation, edge_index, index=node_idx,\n",
    "                                    x=x)\n",
    "\n",
    "    def _convert_output(self, explanation, edge_index, index=None, x=None):\n",
    "        node_mask = explanation.get('node_mask')\n",
    "        edge_mask = explanation.get('edge_mask')\n",
    "\n",
    "        if node_mask is not None:\n",
    "            node_mask_type = self._explainer.explainer_config.node_mask_type\n",
    "            if node_mask_type in {MaskType.object, MaskType.common_attributes}:\n",
    "                node_mask = node_mask.view(-1)\n",
    "\n",
    "        if edge_mask is None:\n",
    "            if index is not None:\n",
    "                _, edge_mask = self._explainer._get_hard_masks(\n",
    "                    self.model, index, edge_index, num_nodes=x.size(0))\n",
    "                edge_mask = edge_mask.to(x.dtype)\n",
    "            else:\n",
    "                edge_mask = torch.ones(edge_index.size(1),\n",
    "                                       device=edge_index.device)\n",
    "\n",
    "        return node_mask, edge_mask\n",
    "\n",
    "#------------\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch_geometric.nn import GNNExplainer\n",
    "\n",
    "# Initialize the GNNExplainer and visualize feature importance for a specific node\n",
    "class LitGNNExplainer:\n",
    "    def __init__(self, model, epochs=max_epochs):\n",
    "        self.model = model\n",
    "        self.explainer = GNNExplainer(model, return_type='log_prob') # Adjust `return_type` as needed\n",
    "\n",
    "    def explain(self, data, target_node):\n",
    "        # Ensure model is in evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Extract data components for the explainer\n",
    "        g = data.test_dataloader().dataset[0]  # Use the first graph in the batch for simplicity\n",
    "        x = g.ndata[model.EMBED]  # Node features\n",
    "        edge_index = torch.stack(g.edges())  # Edge index in the format (2, num_edges)\n",
    "\n",
    "        # Use GNNExplainer to explain the node prediction\n",
    "        feat_mask, edge_mask = self.explainer.explain_node(target_node, x, edge_index)\n",
    "\n",
    "        # Visualize feature importance\n",
    "        self.visualize_feature_importance(feat_mask, x, target_node)\n",
    "\n",
    "    @staticmethod\n",
    "    def visualize_feature_importance(feat_mask, x, target_node):\n",
    "        # Plot feature importance\n",
    "        feat_importance = feat_mask.cpu().detach().numpy()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(len(feat_importance)), feat_importance)\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.title(f'Feature Importance for Node {target_node}')\n",
    "        plt.show()\n",
    "\n",
    "# Instantiate and use the explainer\n",
    "print(f\"----------------------->>> Explaining the model\")\n",
    "\n",
    "explainer = LitGNNExplainer(model)\n",
    "\n",
    "# Load data and choose a target node for explanation\n",
    "data = data.test_dataloader().dataset[0]  # Get a sample batch from the test set\n",
    "target_node ='_E'  # Choose a node index for explanation (replace with a specific index as needed)\n",
    "\n",
    "explainer.explain(data, target_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the graph: 4\n",
      "Node indices: tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "# Create a simple DGL graph\n",
    "edges = (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))  # Define edges\n",
    "g = dgl.graph(edges)  # Create a graph\n",
    "\n",
    "# Get the number of nodes\n",
    "num_nodes = g.num_nodes()\n",
    "print(f\"Number of nodes in the graph: {num_nodes}\")\n",
    "\n",
    "# Get the node indices\n",
    "node_indices = g.nodes()\n",
    "print(\"Node indices:\", node_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
